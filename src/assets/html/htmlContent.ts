// Auto-generated from index.html
// Do not edit manually.
// ‚úÖ Regenerate by running: `node scripts/generateHtmlContent.js`
export const HTML_CONTENT = "<!DOCTYPE html>\n<html>\n\n<head>\n    <meta charset=\"utf-8\" />\n    <title>Random VRM Model & Animation Viewer</title>\n    <meta name=\"viewport\"\n        content=\"width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no\" />\n    <style>\n        html,\n        body {\n            height: 100%;\n            min-height: 100vh;\n            margin: 0;\n            padding: 0;\n            overflow: hidden;\n        }\n\n        body {\n            background-image: url('https://d1j8r0kxyu9tj8.cloudfront.net/files/83HCzduW2U9liGtW3sMUBfJ4Iur2eq42aMdEvarr.png');\n            background-size: cover;\n            background-position: center center;\n            background-repeat: no-repeat;\n        }\n\n        /* Smooth background crossfade overlay */\n        #bgFadeOverlay {\n            position: fixed;\n            top: 0;\n            left: 0;\n            width: 100vw;\n            height: 100vh;\n            background-size: cover;\n            background-position: center center;\n            background-repeat: no-repeat;\n            opacity: 0;\n            transition: opacity 400ms ease;\n            z-index: 0;\n            /* below canvas (z-index:1), above body background */\n            pointer-events: none;\n        }\n\n        #bgVideo {\n            position: fixed;\n            top: 0;\n            left: 0;\n            width: 100vw;\n            height: 100vh;\n            object-fit: cover;\n            z-index: 0;\n            opacity: 0;\n            transition: opacity 400ms ease;\n            pointer-events: none;\n            display: none;\n        }\n\n        /* Call mode background blur layer. We re-use #bgFadeOverlay with this class. */\n        #bgFadeOverlay.call-blur {\n            /* opacity: 1 !important; removed to allow JS transitions */\n            /* ensure visible during call mode */\n            filter: blur(10px) saturate(1.05);\n            /* soft blur with slight pop */\n            transform: scale(1.03);\n            /* hide blur edges */\n        }\n\n        canvas {\n            display: block;\n            position: fixed;\n            top: 0;\n            left: 0;\n            width: 100vw;\n            height: 100vh;\n            z-index: 1;\n        }\n\n\n        #divInfo {\n            position: fixed;\n            background: rgba(255, 255, 255, 0.95);\n            border-radius: 8px;\n            margin: 10px;\n            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);\n            font-family: Arial, sans-serif;\n            z-index: 1000;\n            display: none;\n        }\n\n        #currentFiles {\n            margin-top: 10px;\n            padding-top: 10px;\n            border-top: 1px solid #ccc;\n            font-size: 14px;\n        }\n\n        .file-info {\n            margin: 5px 0;\n            color: #555;\n        }\n\n        .file-name {\n            font-weight: bold;\n            color: #333;\n        }\n\n        #reloadBtn,\n        #nextAnimBtn {\n            padding: 8px 16px;\n            background: #667eea;\n            color: white;\n            border: none;\n            border-radius: 4px;\n            cursor: pointer;\n            font-size: 14px;\n            transition: background 0.3s ease;\n        }\n\n        #reloadBtn:hover,\n        #nextAnimBtn:hover {\n            background: #5a67d8;\n        }\n\n        #nextAnimBtn {\n            background: #48bb78;\n        }\n\n        #nextAnimBtn:hover {\n            background: #38a169;\n        }\n\n        #reloadBtn:disabled,\n        #nextAnimBtn:disabled {\n            opacity: 0.6;\n            cursor: not-allowed;\n        }\n\n        #nextAnimBtn:disabled:hover {\n            background: #48bb78;\n        }\n\n        .lil-gui {\n            display: none !important;\n        }\n\n        /* Floating action buttons (right side) */\n        /* swift overlay buttons will replace web buttons */\n\n\n        /* Loading overlay and blur */\n        #loadingOverlay {\n            position: fixed;\n            top: 0;\n            left: 0;\n            width: 100vw;\n            height: 100vh;\n            display: none;\n            align-items: center;\n            justify-content: center;\n            flex-direction: column;\n            background: rgba(0, 0, 0, 0.25);\n            z-index: 1001;\n            font-family: Arial, sans-serif;\n            color: white;\n            text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);\n        }\n\n        #loadingText {\n            margin-top: 12px;\n            font-size: 16px;\n        }\n\n        .loading-blur {\n            filter: blur(6px) saturate(0.9) brightness(0.95);\n            transition: filter 0.2s ease;\n        }\n    </style>\n</head>\n\n<body>\n    <div id=\"bgFadeOverlay\"></div>\n    <video id=\"bgVideo\" muted loop playsinline></video>\n    <div id=\"loadingOverlay\">\n        <svg width=\"44\" height=\"44\" viewBox=\"0 0 44 44\" xmlns=\"http://www.w3.org/2000/svg\" stroke=\"#fff\">\n            <g fill=\"none\" fill-rule=\"evenodd\" stroke-width=\"4\">\n                <circle cx=\"22\" cy=\"22\" r=\"18\" stroke-opacity=\"0.3\" />\n                <path d=\"M40 22c0-9.94-8.06-18-18-18\" stroke=\"#fff\">\n                    <animateTransform attributeName=\"transform\" type=\"rotate\" from=\"0 22 22\" to=\"360 22 22\" dur=\"1s\"\n                        repeatCount=\"indefinite\" />\n                </path>\n            </g>\n        </svg>\n        <div id=\"loadingText\">Loading... 0%</div>\n    </div>\n    <div id=\"divInfo\">\n        <strong>Random VRM & Animation Loader</strong><br>\n        <span style=\"font-size: 12px; color: #666;\">Drag and drop to override</span>\n        <div id=\"currentFiles\">\n            <div class=\"file-info\">Model: <span id=\"currentModel\" class=\"file-name\">Loading...</span></div>\n            <div class=\"file-info\">Animation: <span id=\"currentAnimation\" class=\"file-name\">Loading...</span></div>\n        </div>\n        <div style=\"display: flex; gap: 8px; margin-top: 10px;\">\n            <button id=\"reloadBtn\" onclick=\"loadRandomFiles()\">Load New Random</button>\n            <button id=\"nextAnimBtn\" onclick=\"loadNextAnimation()\">Next Animation</button>\n        </div>\n    </div>\n\n    <!-- Swift overlay buttons will be added in native UI -->\n\n    <script type=\"importmap\">\n            {\n                \"imports\": {\n                    \"three\": \"https://cdn.jsdelivr.net/npm/three@0.177.0/build/three.module.js\",\n                    \"three/addons/\": \"https://cdn.jsdelivr.net/npm/three@0.177.0/examples/jsm/\",\n                    \"@pixiv/three-vrm\": \"https://cdn.jsdelivr.net/npm/@pixiv/three-vrm@3/lib/three-vrm.module.min.js\"\n                }\n            }\n        </script>\n\n    <script type=\"module\">\n        import * as THREE from 'three';\n        import { GLTFLoader } from 'three/addons/loaders/GLTFLoader.js';\n        import { FBXLoader } from 'three/addons/loaders/FBXLoader.js';\n        import { OrbitControls } from 'three/addons/controls/OrbitControls.js';\n        import { VRMLoaderPlugin, VRMUtils } from '@pixiv/three-vrm';\n        import GUI from 'three/addons/libs/lil-gui.module.min.js';\n\n        // === Inlined from config.js ===\n        const mixamoVRMRigMap = { \"mixamorigHips\": \"hips\", \"mixamorigSpine\": \"spine\", \"mixamorigSpine1\": \"chest\", \"mixamorigSpine2\": \"upperChest\", \"mixamorigNeck\": \"neck\", \"mixamorigHead\": \"head\", \"mixamorigLeftShoulder\": \"leftShoulder\", \"mixamorigLeftArm\": \"leftUpperArm\", \"mixamorigLeftForeArm\": \"leftLowerArm\", \"mixamorigLeftHand\": \"leftHand\", \"mixamorigLeftHandThumb1\": \"leftThumbMetacarpal\", \"mixamorigLeftHandThumb2\": \"leftThumbProximal\", \"mixamorigLeftHandThumb3\": \"leftThumbDistal\", \"mixamorigLeftHandIndex1\": \"leftIndexProximal\", \"mixamorigLeftHandIndex2\": \"leftIndexIntermediate\", \"mixamorigLeftHandIndex3\": \"leftIndexDistal\", \"mixamorigLeftHandMiddle1\": \"leftMiddleProximal\", \"mixamorigLeftHandMiddle2\": \"leftMiddleIntermediate\", \"mixamorigLeftHandMiddle3\": \"leftMiddleDistal\", \"mixamorigLeftHandRing1\": \"leftRingProximal\", \"mixamorigLeftHandRing2\": \"leftRingIntermediate\", \"mixamorigLeftHandRing3\": \"leftRingDistal\", \"mixamorigLeftHandPinky1\": \"leftLittleProximal\", \"mixamorigLeftHandPinky2\": \"leftLittleIntermediate\", \"mixamorigLeftHandPinky3\": \"leftLittleDistal\", \"mixamorigRightShoulder\": \"rightShoulder\", \"mixamorigRightArm\": \"rightUpperArm\", \"mixamorigRightForeArm\": \"rightLowerArm\", \"mixamorigRightHand\": \"rightHand\", \"mixamorigRightHandThumb1\": \"rightThumbMetacarpal\", \"mixamorigRightHandThumb2\": \"rightThumbProximal\", \"mixamorigRightHandThumb3\": \"rightThumbDistal\", \"mixamorigRightHandIndex1\": \"rightIndexProximal\", \"mixamorigRightHandIndex2\": \"rightIndexIntermediate\", \"mixamorigRightHandIndex3\": \"rightIndexDistal\", \"mixamorigRightHandMiddle1\": \"rightMiddleProximal\", \"mixamorigRightHandMiddle2\": \"rightMiddleIntermediate\", \"mixamorigRightHandMiddle3\": \"rightMiddleDistal\", \"mixamorigRightHandRing1\": \"rightRingProximal\", \"mixamorigRightHandRing2\": \"rightRingIntermediate\", \"mixamorigRightHandRing3\": \"rightRingDistal\", \"mixamorigRightHandPinky1\": \"rightLittleProximal\", \"mixamorigRightHandPinky2\": \"rightLittleIntermediate\", \"mixamorigRightHandPinky3\": \"rightLittleDistal\", \"mixamorigLeftUpLeg\": \"leftUpperLeg\", \"mixamorigLeftLeg\": \"leftLowerLeg\", \"mixamorigLeftFoot\": \"leftFoot\", \"mixamorigLeftToeBase\": \"leftToes\", \"mixamorigRightUpLeg\": \"rightUpperLeg\", \"mixamorigRightLeg\": \"rightLowerLeg\", \"mixamorigRightFoot\": \"rightFoot\", \"mixamorigRightToeBase\": \"rightToes\" };\n        const genericVRMRigMap = { \"Hips\": \"hips\", \"Spine\": \"spine\", \"Chest\": \"chest\", \"UpperChest\": \"upperChest\", \"Neck\": \"neck\", \"Head\": \"head\", \"LeftShoulder\": \"leftShoulder\", \"LeftUpperArm\": \"leftUpperArm\", \"LeftLowerArm\": \"leftLowerArm\", \"LeftHand\": \"leftHand\", \"RightShoulder\": \"rightShoulder\", \"RightUpperArm\": \"rightUpperArm\", \"RightLowerArm\": \"rightLowerArm\", \"RightHand\": \"rightHand\", \"LeftUpperLeg\": \"leftUpperLeg\", \"LeftLowerLeg\": \"leftLowerLeg\", \"LeftFoot\": \"leftFoot\", \"LeftToes\": \"leftToes\", \"RightUpperLeg\": \"rightUpperLeg\", \"RightLowerLeg\": \"rightLowerLeg\", \"RightFoot\": \"rightFoot\", \"RightToes\": \"rightToes\", \"hips\": \"hips\", \"spine\": \"spine\", \"chest\": \"chest\", \"upper_chest\": \"upperChest\", \"neck\": \"neck\", \"head\": \"head\", \"shoulder.L\": \"leftShoulder\", \"upper_arm.L\": \"leftUpperArm\", \"forearm.L\": \"leftLowerArm\", \"hand.L\": \"leftHand\", \"shoulder.R\": \"rightShoulder\", \"upper_arm.R\": \"rightUpperArm\", \"forearm.R\": \"rightLowerArm\", \"hand.R\": \"rightHand\", \"thigh.L\": \"leftUpperLeg\", \"shin.L\": \"leftLowerLeg\", \"foot.L\": \"leftFoot\", \"toe.L\": \"leftToes\", \"thigh.R\": \"rightUpperLeg\", \"shin.R\": \"rightLowerLeg\", \"foot.R\": \"rightFoot\", \"toe.R\": \"rightToes\" };\n        const combinedRigMap = { ...genericVRMRigMap, ...mixamoVRMRigMap };\n        const vrmFiles = [\"0001_01 2.vrm\", \"0001_01 3.vrm\", \"0001_02 2.vrm\", \"0001_02 3.vrm\", \"0001_02.vrm\", \"0001_03 2.vrm\", \"0001_03.vrm\", \"0001_04 2.vrm\", \"0001_04.vrm\", \"0001_05 2.vrm\", \"0001_05.vrm\", \"0001_06 2.vrm\", \"0001_06.vrm\", \"0001_07 2.vrm\", \"0001_07 3.vrm\", \"0001_07.vrm 2\", \"0001_07.vrm\", \"0001_08 2.vrm\", \"0001_08 3.vrm\", \"0001_08.vrm 2\", \"0001_08.vrm\", \"0001_09 2.vrm\", \"0001_09.vrm\", \"0001_10.vrm\"];\n        const fbxFiles = [\"Angry.fbx\", \"Bashful.fbx\", \"Blow A Kiss.fbx\", \"Booty Hip Hop Dance.fbx\", \"Cross Jumps.fbx\", \"Hand Raising.fbx\", \"Happy.fbx\", \"Hip Hop Dancing.fbx\", \"Idle Stand.fbx\", \"Jumping Jacks.fbx\", \"Quick Steps.fbx\", \"Rumba Dancing.fbx\", \"Snake Hip Hop Dance.fbx\", \"Standing Arguing.fbx\", \"Standing Greeting.fbx\", \"Step Hip Hop Dance.fbx\", \"Talking.fbx\", \"Taunt.fbx\", \"Thinking.fbx\", \"Threatening.fbx\"];\n        const VRM_BASE_URL = 'https://n6n.top/Model/';\n        const FBX_BASE_URL = 'https://n6n.top/Anim/';\n        // Background music is controlled exclusively by Swift; no HTML-side audio.\n        const namePatterns = { hips: /hip/i, spine: /spine/i, chest: /chest|spine1/i, upperChest: /upperchest|spine2/i, neck: /neck/i, head: /head/i, leftShoulder: /l(eft)?[-_\\s]?shoulder/i, leftUpperArm: /l(eft)?[-_\\s]?(upper)?[-_\\s]?arm/i, leftLowerArm: /l(eft)?[-_\\s]?(lower|fore)[-_\\s]?arm/i, leftHand: /l(eft)?[-_\\s]?hand/i, rightShoulder: /r(ight)?[-_\\s]?shoulder/i, rightUpperArm: /r(ight)?[-_\\s]?(upper)?[-_\\s]?arm/i, rightLowerArm: /r(ight)?[-_\\s]?(lower|fore)[-_\\s]?arm/i, rightHand: /r(ight)?[-_\\s]?hand/i, leftUpperLeg: /l(eft)?[-_\\s]?(upper|up)[-_\\s]?leg|l(eft)?[-_\\s]?thigh/i, leftLowerLeg: /l(eft)?[-_\\s]?(lower)?[-_\\s]?leg|l(eft)?[-_\\s]?(shin|calf)/i, leftFoot: /l(eft)?[-_\\s]?foot/i, leftToes: /l(eft)?[-_\\s]?(toe|toebase)/i, rightUpperLeg: /r(ight)?[-_\\s]?(upper|up)[-_\\s]?leg|r(ight)?[-_\\s]?thigh/i, rightLowerLeg: /r(ight)?[-_\\s]?(lower)?[-_\\s]?leg|r(ight)?[-_\\s]?(shin|calf)/i, rightFoot: /r(ight)?[-_\\s]?foot/i, rightToes: /r(ight)?[-_\\s]?(toe|toebase)/i };\n        // === End inlined config ===\n\n        // === Background preloading and cache ===\n        const modelObjectURLCache = new Map(); // name -> Promise<objectURL>\n        const animObjectURLCache = new Map();  // name -> Promise<objectURL>\n        let preloadingStarted = false;\n\n        // Splash gating: wait for first animation and background to be applied\n        let initialAnimationApplied = false;\n        let initialBackgroundReady = false;\n        let progress100At = null; // timestamp when progress reached 100%\n        let overlayHiddenAt = null; // timestamp when loading overlay was hidden\n        let notifyTimer = null;\n        function notifyInitialReadyIfDone() {\n            try {\n                console.log('üîç Checking initial ready:', {\n                    animationApplied: initialAnimationApplied,\n                    backgroundReady: initialBackgroundReady,\n                    progress100: progress100At,\n                    overlayHidden: overlayHiddenAt\n                });\n\n                if (!(initialAnimationApplied && initialBackgroundReady)) {\n                    console.log('‚è≥ Waiting for:', {\n                        needAnimation: !initialAnimationApplied,\n                        needBackground: !initialBackgroundReady\n                    });\n                    return;\n                }\n\n                const now = performance.now();\n                const t100 = progress100At ?? now;\n                const thide = overlayHiddenAt ?? now;\n                const target = Math.max(t100, thide) + 1000; // 1s after 100% + overlay hidden\n                const waitMs = target - now;\n\n                const sendReady = () => {\n                    try {\n                        console.log('‚úÖ Sending initialReady message...');\n                        // iOS native WebKit message handler\n                        window.webkit?.messageHandlers?.loading?.postMessage('initialReady');\n                    } catch (e) {\n                        console.error('Error sending to webkit:', e);\n                    }\n                    try {\n                        // React Native WebView message handler\n                        if (window.ReactNativeWebView) {\n                            window.ReactNativeWebView.postMessage('initialReady');\n                            console.log('‚úÖ Sent initialReady to ReactNativeWebView');\n                        } else {\n                            console.warn('‚ö†Ô∏è window.ReactNativeWebView not available');\n                        }\n                    } catch (e) {\n                        console.error('Error sending to ReactNativeWebView:', e);\n                    }\n                };\n\n                if (waitMs <= 0) {\n                    sendReady();\n                } else {\n                    console.log(`‚è≥ Waiting ${waitMs}ms before sending initialReady...`);\n                    if (notifyTimer) { clearTimeout(notifyTimer); }\n                    notifyTimer = setTimeout(() => {\n                        console.log('‚è∞ Timer fired, sending initialReady');\n                        sendReady();\n                    }, waitMs);\n                }\n            } catch (e) {\n                console.error('Error in notifyInitialReadyIfDone:', e);\n            }\n        }\n\n        function fetchAndCacheObjectURL(name, baseUrl, cacheMap) {\n            if (cacheMap.has(name)) return cacheMap.get(name);\n            const url = baseUrl + encodeURIComponent(name);\n            const promise = fetch(url, { mode: 'cors' })\n                .then(r => {\n                    if (!r.ok) throw new Error('HTTP ' + r.status + ' for ' + name);\n                    return r.blob();\n                })\n                .then(blob => URL.createObjectURL(blob))\n                .catch(err => {\n                    cacheMap.delete(name);\n                    throw err;\n                });\n            cacheMap.set(name, promise);\n            return promise;\n        }\n\n        async function withConcurrency(names, worker, concurrency = 3) {\n            const queue = names.slice();\n            const running = [];\n            const results = [];\n            while (queue.length > 0 || running.length > 0) {\n                while (running.length < concurrency && queue.length > 0) {\n                    const name = queue.shift();\n                    const p = Promise.resolve().then(() => worker(name))\n                        .then(res => ({ status: 'fulfilled', value: res, name }))\n                        .catch(err => ({ status: 'rejected', reason: err, name }));\n                    running.push(p);\n                }\n                const settled = await Promise.race(running.map((p, i) => p.then(v => ({ v, i }))));\n                running.splice(settled.i, 1);\n                results.push(settled.v);\n            }\n            return results;\n        }\n\n        async function startBackgroundPreloading(excludeModelName = null, excludeAnimationName = null) {\n            if (preloadingStarted) return;\n            preloadingStarted = true;\n            try {\n                const modelNames = vrmFiles.filter(n => n !== excludeModelName);\n                const animNames = fbxFiles.filter(n => n !== excludeAnimationName);\n                // Kick off both in parallel\n                await Promise.all([\n                    withConcurrency(modelNames, (name) => fetchAndCacheObjectURL(name, VRM_BASE_URL, modelObjectURLCache), 2),\n                    withConcurrency(animNames, (name) => fetchAndCacheObjectURL(name, FBX_BASE_URL, animObjectURLCache), 3)\n                ]);\n                /* preloading completed */\n            } catch (e) {\n                /* background preloading finished with some errors */\n            }\n        }\n\n        async function getModelURL(name) {\n            if (!name) return null;\n            if (modelObjectURLCache.has(name)) {\n                try { return await modelObjectURLCache.get(name); } catch { /* fallthrough */ }\n            }\n            // If not cached, return remote URL and also start caching in background\n            const remote = VRM_BASE_URL + encodeURIComponent(name);\n            fetchAndCacheObjectURL(name, VRM_BASE_URL, modelObjectURLCache);\n            return remote;\n        }\n\n        async function getAnimationURL(name) {\n            if (!name) return null;\n            if (animObjectURLCache.has(name)) {\n                try { return await animObjectURLCache.get(name); } catch { /* fallthrough */ }\n            }\n            const remote = FBX_BASE_URL + encodeURIComponent(name);\n            fetchAndCacheObjectURL(name, FBX_BASE_URL, animObjectURLCache);\n            return remote;\n        }\n\n        function safeFileNameFromUrl(url) {\n            try {\n                // Handle blob: URLs and http(s): URLs\n                if (!url) return null;\n                const last = url.split('/').pop() || '';\n                try { return decodeURIComponent(last); } catch { return last; }\n            } catch {\n                return null;\n            }\n        }\n\n        function findBoneMapping(boneName) {\n            if (combinedRigMap[boneName]) {\n                return combinedRigMap[boneName];\n            }\n            const lowerName = boneName.toLowerCase();\n            for (const [key, value] of Object.entries(combinedRigMap)) {\n                if (key.toLowerCase() === lowerName) {\n                    return value;\n                }\n            }\n            for (const [vrmBone, pattern] of Object.entries(namePatterns)) {\n                if (pattern.test(boneName)) {\n                    return vrmBone;\n                }\n            }\n            return null;\n        }\n\n        function loadHumanoidAnimation(url, vrm) {\n            const loader = new FBXLoader();\n            loader.crossOrigin = 'anonymous';\n            return loader.loadAsync(url).then((asset) => {\n                let clip = THREE.AnimationClip.findByName(asset.animations, 'mixamo.com');\n                if (!clip && asset.animations.length > 0) {\n                    clip = asset.animations[0];\n                }\n                if (!clip) {\n                    throw new Error('No animation found in FBX file');\n                }\n                const tracks = [];\n                const restRotationInverse = new THREE.Quaternion();\n                const parentRestWorldRotation = new THREE.Quaternion();\n                const _quatA = new THREE.Quaternion();\n                const _vec3 = new THREE.Vector3();\n                let hipsNode = null;\n                asset.traverse((node) => {\n                    if (!hipsNode) {\n                        const vrmBoneName = findBoneMapping(node.name);\n                        if (vrmBoneName === 'hips') {\n                            hipsNode = node;\n                        }\n                    }\n                });\n                let hipsPositionScale = 1.0;\n                if (hipsNode) {\n                    const motionHipsHeight = hipsNode.position.y;\n                    const vrmHipsY = vrm.humanoid?.getNormalizedBoneNode('hips')?.getWorldPosition(_vec3).y || 1;\n                    const vrmRootY = vrm.scene.getWorldPosition(_vec3).y;\n                    const vrmHipsHeight = Math.abs(vrmHipsY - vrmRootY);\n                    if (motionHipsHeight > 0) {\n                        hipsPositionScale = vrmHipsHeight / motionHipsHeight;\n                    }\n                }\n                clip.tracks.forEach((track) => {\n                    const trackSplitted = track.name.split('.');\n                    const rigBoneName = trackSplitted[0];\n                    const vrmBoneName = findBoneMapping(rigBoneName);\n                    if (!vrmBoneName) {\n                        return;\n                    }\n                    const vrmNodeName = vrm.humanoid?.getNormalizedBoneNode(vrmBoneName)?.name;\n                    const rigNode = asset.getObjectByName(rigBoneName);\n                    if (vrmNodeName != null && rigNode) {\n                        const propertyName = trackSplitted[1];\n                        rigNode.getWorldQuaternion(restRotationInverse).invert();\n                        rigNode.parent.getWorldQuaternion(parentRestWorldRotation);\n                        if (track instanceof THREE.QuaternionKeyframeTrack) {\n                            for (let i = 0; i < track.values.length; i += 4) {\n                                const flatQuaternion = track.values.slice(i, i + 4);\n                                _quatA.fromArray(flatQuaternion);\n                                _quatA.premultiply(parentRestWorldRotation).multiply(restRotationInverse);\n                                _quatA.toArray(flatQuaternion);\n                                flatQuaternion.forEach((v, index) => {\n                                    track.values[index + i] = v;\n                                });\n                            }\n                            tracks.push(\n                                new THREE.QuaternionKeyframeTrack(\n                                    `${vrmNodeName}.${propertyName}`,\n                                    track.times,\n                                    track.values.map((v, i) => (vrm.meta?.metaVersion === '0' && i % 2 === 0 ? - v : v)),\n                                ),\n                            );\n                        } else if (track instanceof THREE.VectorKeyframeTrack) {\n                            const value = track.values.map((v, i) => (vrm.meta?.metaVersion === '0' && i % 3 !== 1 ? - v : v) * hipsPositionScale);\n                            tracks.push(new THREE.VectorKeyframeTrack(`${vrmNodeName}.${propertyName}`, track.times, value));\n                        }\n                    }\n                });\n                return new THREE.AnimationClip('vrmAnimation', clip.duration, tracks);\n            });\n        }\n\n        const renderer = new THREE.WebGLRenderer({ alpha: true, antialias: true });\n        renderer.setSize(window.innerWidth, window.innerHeight);\n        renderer.setPixelRatio(window.devicePixelRatio);\n        renderer.setClearColor(0x000000, 0);\n        document.body.appendChild(renderer.domElement);\n\n        const camera = new THREE.PerspectiveCamera(30.0, window.innerWidth / window.innerHeight, 0.1, 20.0);\n        // Camera state with smooth lerp to support call mode zooming\n        // Default (non-call): slightly zoomed in on body, targeting waist (y=1.05, z=3.0)\n        camera.position.set(0.0, 1.05, 3.0);\n        const __camDesiredPos = new THREE.Vector3(0.0, 1.05, 3.0);\n        const __camDesiredTarget = new THREE.Vector3(0.0, 1.05, 0.0);\n        let __callMode = false;\n        const __tmpVec3 = new THREE.Vector3();\n\n        const controls = new OrbitControls(camera, renderer.domElement);\n        controls.screenSpacePanning = true;\n        controls.target.set(0.0, 1.05, 0.0);\n        controls.update();\n        controls.enabled = false;\n\n        const scene = new THREE.Scene();\n\n        // Transparent background for embedding\n        scene.background = null;\n\n        const light = new THREE.DirectionalLight(0xffffff, Math.PI);\n        light.position.set(1.0, 1.0, 1.0).normalize();\n        scene.add(light);\n\n        const ambientLight = new THREE.AmbientLight(0xffffff, 0.4);\n        scene.add(ambientLight);\n\n        let currentVrm = undefined;\n        let currentAnimationUrl = undefined;\n        let currentMixer = undefined;\n        let currentAction = undefined;\n        let lastUsedAnimationIndex = -1;\n        let blinkInterval = undefined;\n        // Removed HTML-side BGM variables; Swift manages all music playback.\n        let smileController = undefined;\n        let ambientController = undefined;\n        let postLoadBlurTimerId = undefined;\n\n        // Utilities for call mode camera and background\n        function __applyCallBackgroundBlur(enabled) {\n            try {\n                const overlay = document.getElementById('bgFadeOverlay');\n                if (!overlay) return;\n                if (enabled) {\n                    // Mirror body's current background to overlay to blur it\n                    const bodyBg = window.getComputedStyle(document.body).backgroundImage;\n                    if (bodyBg && bodyBg !== 'none') {\n                        // Extract URL('...') and apply directly; if smoothSetBackground has a newer url it will override shortly\n                        overlay.style.backgroundImage = bodyBg;\n                    }\n                    overlay.classList.add('call-blur');\n                    overlay.style.opacity = '1';\n                } else {\n                    overlay.classList.remove('call-blur');\n                    overlay.style.opacity = '0';\n                }\n            } catch { }\n        }\n\n        function __updateCameraTargetsForMode() {\n            // Default framing\n            let targetY = 1.05;\n            let posZ = __callMode ? 1.8 : 3.0; // closer in call mode, default 3.0 for body shot\n            let fov = __callMode ? 24.0 : 30.0; // slightly tighter FOV\n\n            // If we have a VRM, try to focus on the head for better framing\n            try {\n                if (__callMode && currentVrm && currentVrm.humanoid) {\n                    const wp = new THREE.Vector3();\n                    const head = currentVrm.humanoid.getNormalizedBoneNode('head');\n                    if (head) {\n                        head.getWorldPosition(wp);\n                        __camDesiredTarget.set(wp.x, wp.y, wp.z);\n                        targetY = wp.y;\n                    } else {\n                        __camDesiredTarget.set(0.0, targetY, 0.0);\n                    }\n                } else {\n                    // Non-call mode: focus on waist (1.05)\n                    __camDesiredTarget.set(0.0, 1.05, 0.0);\n                    targetY = 1.05;\n                }\n            } catch {\n                __camDesiredTarget.set(0.0, 1.05, 0.0);\n                targetY = 1.05;\n            }\n\n            // Place camera in front of the target along Z axis in world space\n            __camDesiredPos.set(__camDesiredTarget.x, targetY, __camDesiredTarget.z + posZ);\n            camera.fov = fov;\n            camera.updateProjectionMatrix();\n        }\n\n        // Public API for native: enable/disable call mode\n        window.setCallMode = function (enabled) {\n            try {\n                __callMode = !!enabled;\n                __applyCallBackgroundBlur(__callMode);\n                __updateCameraTargetsForMode();\n            } catch { }\n        };\n\n        window.isCallModeActive = function () { return !!__callMode; };\n\n        const helperRoot = new THREE.Group();\n        helperRoot.renderOrder = 10000;\n        helperRoot.visible = false;\n        scene.add(helperRoot);\n\n        // Loading UI helpers\n        function setModelLoading(isLoading) {\n            try {\n                const overlay = document.getElementById('loadingOverlay');\n                const canvas = renderer?.domElement;\n                if (!overlay || !canvas) return;\n                overlay.style.display = isLoading ? 'flex' : 'none';\n                // Manage blur on canvas: blur while loading, remove when loaded\n                if (isLoading) {\n                    if (postLoadBlurTimerId) { clearTimeout(postLoadBlurTimerId); postLoadBlurTimerId = undefined; }\n                    canvas.classList.add('loading-blur');\n                } else {\n                    if (postLoadBlurTimerId) { clearTimeout(postLoadBlurTimerId); postLoadBlurTimerId = undefined; }\n                    try { canvas.classList.remove('loading-blur'); } catch { }\n                    try { overlayHiddenAt = performance.now(); } catch { }\n                    try {\n                        if (currentAnimationUrl) {\n                            const name = safeFileNameFromUrl(currentAnimationUrl) || 'Animation';\n                            loadFBX(currentAnimationUrl, name, 0.5);\n                        } else if (lastUsedAnimationIndex === -1) {\n                            const idleName = getDefaultIdleAnimation();\n                            if (idleName) {\n                                getAnimationURL(idleName).then(u => { if (u) loadFBX(u, idleName, 0.5); });\n                            }\n                        } else if (window.loadNextAnimation) {\n                            window.loadNextAnimation();\n                        }\n                    } catch { }\n                }\n                const text = document.getElementById('loadingText');\n                if (!isLoading && text) text.textContent = 'Loading... 0%';\n            } catch { }\n        }\n        function updateLoadingProgress(percent) {\n            try {\n                const text = document.getElementById('loadingText');\n                if (text) text.textContent = `Loading... ${Math.max(0, Math.min(100, percent | 0))}%`;\n                if ((percent | 0) >= 100 && progress100At == null) { try { progress100At = performance.now(); notifyInitialReadyIfDone(); } catch { } }\n            } catch { }\n        }\n\n        function getRandomItem(array) {\n            if (!array || array.length === 0) return null;\n            return array[Math.floor(Math.random() * array.length)];\n        }\n\n        function getNextAnimation() {\n            if (!fbxFiles || fbxFiles.length === 0) return null;\n            let attempts = 0;\n            let randomIndex;\n            let randomFBX;\n            do {\n                randomIndex = Math.floor(Math.random() * fbxFiles.length);\n                randomFBX = fbxFiles[randomIndex];\n                attempts++;\n            } while (randomIndex === lastUsedAnimationIndex && attempts < 10 && fbxFiles.length > 1);\n            lastUsedAnimationIndex = randomIndex;\n            return randomFBX;\n        }\n\n        // Calm default animation for first-time auto-play\n        function getDefaultIdleAnimation() {\n            if (!fbxFiles || fbxFiles.length === 0) return null;\n            const priorities = [\n                /idle/i,\n                /stand/i,\n                /greet|greeting|hello|wave/i,\n                /hand\\s*raising/i,\n                /talk/i\n            ];\n            for (const p of priorities) {\n                const match = fbxFiles.find(name => p.test(name));\n                if (match) return match;\n            }\n            return null;\n        }\n\n        function updateFileDisplay(modelName, animationName) {\n            document.getElementById('currentModel').textContent = modelName || 'None';\n            document.getElementById('currentAnimation').textContent = animationName || 'None';\n        }\n\n        let expressionsFolder = null;\n        let expressionParams = {};\n\n        const commonExpressions = [\n            'blink', 'blinkLeft', 'blinkRight', 'wink', 'winkLeft', 'winkRight',\n            'aa', 'ih', 'ou', 'ee', 'oh', 'teethOpen',\n            'lookUp', 'lookDown', 'lookLeft', 'lookRight',\n            'happy', 'relaxed', 'surprised', 'angry', 'sad', 'fun', 'lowered', 'raised', 'joy'\n        ];\n\n        function setupBlendshapes(vrm) {\n            if (!vrm || !vrm.expressionManager) {\n                return;\n            }\n            if (expressionsFolder) {\n                gui.removeFolder(expressionsFolder);\n                expressionsFolder = null;\n                expressionParams = {};\n            }\n            expressionsFolder = gui.addFolder('Expressions');\n            let validExpressions = [];\n            if (vrm.expressionManager.expressionMap) {\n                validExpressions = Object.keys(vrm.expressionManager.expressionMap);\n            } else if (vrm.expressionManager._expressionMap) {\n                validExpressions = Object.keys(vrm.expressionManager._expressionMap);\n            } else if (vrm.expressionManager.expressions) {\n                validExpressions = Object.keys(vrm.expressionManager.expressions);\n            } else if (Array.isArray(vrm.expressionManager.blinkExpressionNames)) {\n                validExpressions = [\n                    ...vrm.expressionManager.blinkExpressionNames,\n                    ...(vrm.expressionManager.mouthExpressionNames || []),\n                    ...(vrm.expressionManager.lookAtExpressionNames || [])\n                ];\n            } else {\n                validExpressions = commonExpressions;\n            }\n            for (const name of validExpressions) {\n                if (Object.prototype.hasOwnProperty.call(expressionParams, name)) continue;\n                expressionParams[name] = 0.0;\n                try {\n                    const controller = expressionsFolder.add(expressionParams, name, 0.0, 1.0, 0.01);\n                    controller.onChange((value) => {\n                        if (vrm && vrm.expressionManager) {\n                            try {\n                                vrm.expressionManager.setValue(name, value);\n                            } catch { }\n                        }\n                    });\n                } catch {\n                    delete expressionParams[name];\n                }\n            }\n            if (Object.keys(expressionParams).length > 0) {\n                expressionsFolder.open();\n            }\n        }\n\n        function startRandomBlinking(vrm) {\n            if (!vrm || !vrm.expressionManager) return;\n            stopRandomBlinking();\n            // Store reference to current vrm for this instance\n            const targetVrm = vrm;\n            console.log('Starting blinking for VRM:', vrm);\n            const blinkExpressions = ['blink', 'blinkLeft', 'blinkRight', 'Blink', 'eyesClosed'];\n            let blinkAnimationFrame = null;\n            let blinkStartTime = 0;\n            let isBlinking = false;\n            let currentBlinkValue = 0.0;\n            const animateBlink = (timestamp) => {\n                if (!isBlinking) {\n                    blinkAnimationFrame = requestAnimationFrame(animateBlink);\n                    return;\n                }\n                const elapsed = (timestamp - blinkStartTime) / 1000;\n                const blinkDuration = 0.15;\n                if (elapsed < blinkDuration) {\n                    let blinkProgress;\n                    if (elapsed < blinkDuration / 2) {\n                        blinkProgress = 0.5 * (1 - Math.cos(Math.PI * elapsed / (blinkDuration / 2)));\n                    } else {\n                        const openElapsed = elapsed - blinkDuration / 2;\n                        blinkProgress = 0.5 * (1 + Math.cos(Math.PI * openElapsed / (blinkDuration / 2)));\n                    }\n                    currentBlinkValue = Math.min(1.0, blinkProgress);\n                    if (targetVrm && targetVrm.expressionManager) {\n                        for (const blinkName of blinkExpressions) {\n                            try { targetVrm.expressionManager.setValue(blinkName, currentBlinkValue); } catch { }\n                        }\n                    }\n                    blinkAnimationFrame = requestAnimationFrame(animateBlink);\n                } else {\n                    isBlinking = false;\n                    currentBlinkValue = 0.0;\n                    if (targetVrm && targetVrm.expressionManager) {\n                        for (const blinkName of blinkExpressions) {\n                            try { targetVrm.expressionManager.setValue(blinkName, 0.0); } catch { }\n                        }\n                    }\n                }\n            };\n            blinkAnimationFrame = requestAnimationFrame(animateBlink);\n            const performBlink = () => {\n                if (!targetVrm || !targetVrm.expressionManager || isBlinking) return;\n                console.log('üëÅÔ∏è [Blink] Performing blink animation');\n                isBlinking = true;\n                blinkStartTime = performance.now();\n            };\n            let scheduleTimeout = null;\n            const scheduleBlink = () => {\n                // While speaking, blink more often (1‚Äì2s). Otherwise 1‚Äì3s.\n                const speaking = performance.now() < __speechActiveUntil;\n                const randomInterval = speaking ? (Math.random() * 1 + 1) * 1000 : (Math.random() * 2 + 1) * 1000;\n                scheduleTimeout = setTimeout(() => {\n                    performBlink();\n                    scheduleBlink();\n                }, randomInterval);\n            };\n            scheduleBlink();\n            blinkInterval = {\n                cancel: () => {\n                    cancelAnimationFrame(blinkAnimationFrame);\n                    if (scheduleTimeout) {\n                        clearTimeout(scheduleTimeout);\n                        scheduleTimeout = null;\n                    }\n                }\n            };\n        }\n\n        function stopRandomBlinking() {\n            if (blinkInterval) {\n                if (blinkInterval.cancel) { blinkInterval.cancel(); }\n                blinkInterval = undefined;\n            }\n        }\n\n        // Periodic smiling similar to blinking\n        function startRandomSmiling(vrm) {\n            if (!vrm || !vrm.expressionManager) return;\n            stopRandomSmiling();\n            const targetVrm = vrm;\n            console.log('Starting smiling for VRM:', vrm);\n            const smileExpressions = ['happy', 'joy', 'Joy', 'smile', 'Smile', 'fun', 'relaxed', 'smileOpen'];\n            let smileAnimationFrame = null;\n            let smileStartTime = 0;\n            let isSmiling = false;\n            let phase = 'in'; // 'in' -> 'hold' -> 'out'\n            const durations = { in: 0.3, hold: 0.25, out: 0.3 };\n            const maxSmile = 0.22; // subtle peak intensity\n\n            const setSmileValue = (v) => {\n                if (targetVrm && targetVrm.expressionManager) {\n                    for (const n of smileExpressions) {\n                        try { targetVrm.expressionManager.setValue(n, v); } catch { }\n                    }\n                }\n            };\n\n            const animateSmile = (timestamp) => {\n                if (!isSmiling) {\n                    smileAnimationFrame = requestAnimationFrame(animateSmile);\n                    return;\n                }\n                const t = (timestamp - smileStartTime) / 1000;\n                let value = 0.0;\n                if (phase === 'in') {\n                    const p = Math.min(1, t / durations.in);\n                    value = 0.5 * (1 - Math.cos(Math.PI * p)); // ease-in\n                    if (p >= 1) { phase = 'hold'; smileStartTime = timestamp; }\n                } else if (phase === 'hold') {\n                    value = 1.0;\n                    if (t >= durations.hold) { phase = 'out'; smileStartTime = timestamp; }\n                } else {\n                    const p = Math.min(1, t / durations.out);\n                    value = 1 - 0.5 * (1 - Math.cos(Math.PI * p)); // ease-out\n                    if (p >= 1) { isSmiling = false; value = 0.0; }\n                }\n                const clamped = Math.max(0, Math.min(1, value));\n                setSmileValue(maxSmile * clamped);\n                smileAnimationFrame = requestAnimationFrame(animateSmile);\n            };\n            smileAnimationFrame = requestAnimationFrame(animateSmile);\n\n            const performSmile = () => {\n                if (!targetVrm || !targetVrm.expressionManager || isSmiling) return;\n                isSmiling = true;\n                phase = 'in';\n                smileStartTime = performance.now();\n            };\n\n            let smileScheduleTimeout = null;\n            const scheduleSmile = () => {\n                const intervalMs = (Math.random() * 5 + 5) * 1000; // 5-10s\n                smileScheduleTimeout = setTimeout(() => {\n                    performSmile();\n                    scheduleSmile();\n                }, intervalMs);\n            };\n            scheduleSmile();\n            smileController = {\n                cancel: () => {\n                    cancelAnimationFrame(smileAnimationFrame);\n                    if (smileScheduleTimeout) {\n                        clearTimeout(smileScheduleTimeout);\n                        smileScheduleTimeout = null;\n                    }\n                },\n                clear: () => setSmileValue(0.0)\n            };\n        }\n\n        function stopRandomSmiling() {\n            if (smileController) {\n                try { if (smileController.clear) smileController.clear(); } catch { }\n                try { if (smileController.cancel) smileController.cancel(); } catch { }\n                smileController = undefined;\n            }\n        }\n\n        // Ambient micro-expressions: randomly trigger subtle positive expressions with random intensity/duration\n        function startAmbientMicroExpressions(vrm) {\n            if (!vrm || !vrm.expressionManager) return;\n            stopAmbientMicroExpressions();\n            const targetVrm = vrm;\n            console.log('Starting ambient expressions for VRM:', vrm);\n            const positiveCandidates = [\n                'happy', 'joy', 'fun', 'relaxed', 'lowered', 'raised', // generic positive/eyebrow\n                'ee', 'oh', 'aa', 'ih', 'ou' // subtle mouth shapes (speech-like micro-movements)\n            ];\n\n            let raf = null;\n            let active = false;\n            let startTime = 0;\n            let duration = 0.6;\n            let maxIntensity = 0.15;\n            let targetNames = [];\n            let phase = 'in';\n\n            const setValues = (v) => {\n                if (targetVrm && targetVrm.expressionManager) {\n                    for (const n of targetNames) {\n                        try { targetVrm.expressionManager.setValue(n, v); } catch { }\n                    }\n                }\n            };\n\n            const chooseTargets = () => {\n                // Choose 1‚Äì2 expressions randomly\n                const count = Math.random() < 0.65 ? 1 : 2;\n                const picks = [];\n                const pool = positiveCandidates.slice();\n                while (picks.length < count && pool.length > 0) {\n                    const i = (Math.random() * pool.length) | 0;\n                    picks.push(pool.splice(i, 1)[0]);\n                }\n                return picks;\n            };\n\n            const animate = (ts) => {\n                if (!active) { raf = requestAnimationFrame(animate); return; }\n                const t = (ts - startTime) / 1000;\n                let value = 0.0;\n                const inDur = duration * 0.35;\n                const holdDur = duration * 0.3;\n                const outDur = duration * 0.35;\n                if (phase === 'in') {\n                    const p = Math.min(1, t / inDur);\n                    value = 0.5 * (1 - Math.cos(Math.PI * p));\n                    if (p >= 1) { phase = 'hold'; startTime = ts; }\n                } else if (phase === 'hold') {\n                    value = 1.0;\n                    if (t >= holdDur) { phase = 'out'; startTime = ts; }\n                } else {\n                    const p = Math.min(1, t / outDur);\n                    value = 1 - 0.5 * (1 - Math.cos(Math.PI * p));\n                    if (p >= 1) { active = false; value = 0.0; }\n                }\n                setValues(maxIntensity * Math.max(0, Math.min(1, value)));\n                raf = requestAnimationFrame(animate);\n            };\n            raf = requestAnimationFrame(animate);\n\n            const trigger = () => {\n                if (!targetVrm || !targetVrm.expressionManager || active) return;\n                // Randomize parameters per event\n                targetNames = chooseTargets();\n                maxIntensity = 0.07 + Math.random() * 0.13; // 0.07‚Äì0.20\n                duration = 0.5 + Math.random() * 0.7; // 0.5‚Äì1.2s\n                phase = 'in';\n                active = true;\n                startTime = performance.now();\n            };\n\n            let ambientScheduleTimeout = null;\n            const schedule = () => {\n                const interval = (Math.random() * 4 + 3.5) * 1000; // 3.5‚Äì7.5s\n                ambientScheduleTimeout = setTimeout(() => {\n                    trigger();\n                    schedule();\n                }, interval);\n            };\n            schedule();\n            ambientController = {\n                cancel: () => {\n                    cancelAnimationFrame(raf);\n                    if (ambientScheduleTimeout) {\n                        clearTimeout(ambientScheduleTimeout);\n                        ambientScheduleTimeout = null;\n                    }\n                },\n                clear: () => setValues(0.0)\n            };\n        }\n\n        function stopAmbientMicroExpressions() {\n            if (ambientController) {\n                try { if (ambientController.clear) ambientController.clear(); } catch { }\n                try { if (ambientController.cancel) ambientController.cancel(); } catch { }\n                ambientController = undefined;\n            }\n        }\n\n        function loadVRM(modelUrl, modelName, animationToLoad = null) {\n            const loader = new GLTFLoader();\n            loader.crossOrigin = 'anonymous';\n            helperRoot.clear();\n            loader.register((parser) => new VRMLoaderPlugin(parser, { helperRoot: helperRoot, autoUpdateHumanBones: true }));\n            // show loading overlay\n            setModelLoading(true);\n            loader.load(\n                modelUrl,\n                (gltf) => {\n                    const vrm = gltf.userData.vrm;\n                    VRMUtils.removeUnnecessaryVertices(gltf.scene);\n                    VRMUtils.combineSkeletons(gltf.scene);\n                    // Don't combine morphs - it interferes with expression blendshapes\n                    // VRMUtils.combineMorphs( vrm );\n                    if (currentVrm) {\n                        stopRandomBlinking();\n                        stopRandomSmiling();\n                        stopAmbientMicroExpressions();\n                        scene.remove(currentVrm.scene);\n                        VRMUtils.deepDispose(currentVrm.scene);\n                    }\n                    currentVrm = vrm;\n                    scene.add(vrm.scene);\n                    currentMixer = new THREE.AnimationMixer(currentVrm.scene);\n                    // Clear any previous action from old mixer to avoid cross-fading across mixers\n                    currentAction = undefined;\n                    vrm.scene.traverse((obj) => { obj.frustumCulled = false; });\n                    VRMUtils.rotateVRM0(vrm);\n                    updateFileDisplay(modelName, document.getElementById('currentAnimation').textContent);\n                    setupBlendshapes(vrm);\n\n                    // Start expressions after animation is applied\n                    const startExpressions = () => {\n                        startRandomBlinking(vrm);\n                        startRandomSmiling(vrm);\n                        startAmbientMicroExpressions(vrm);\n                    };\n\n                    if (animationToLoad) {\n                        // Defer auto-play until post-load blur finishes; only set the selected animation name\n                        (async () => {\n                            try {\n                                const animName = safeFileNameFromUrl(animationToLoad);\n                                currentAnimationUrl = animationToLoad;\n                                updateFileDisplay(modelName, animName || 'Animation');\n                            } catch { }\n                        })();\n                    } else {\n                        // No animation to load, start expressions after a short delay\n                        setTimeout(startExpressions, 500);\n                    }\n                    // Notify Swift that model is loaded and scene attached\n                    try { window.webkit?.messageHandlers?.loading?.postMessage('modelLoaded'); } catch { }\n                    try { if (window.ReactNativeWebView) window.ReactNativeWebView.postMessage('modelLoaded'); } catch { }\n                    // hide loading overlay\n                    setModelLoading(false);\n\n                    // Re-evaluate desired camera framing after model attaches\n                    try { __updateCameraTargetsForMode(); } catch { }\n                },\n                (progress) => {\n                    const percent = progress.total ? (100.0 * (progress.loaded / progress.total)) : 0;\n                    updateFileDisplay(`Loading... ${percent.toFixed(0)}%`, document.getElementById('currentAnimation').textContent);\n                    updateLoadingProgress(percent);\n                },\n                (error) => {\n                    /* error loading VRM */\n                    updateFileDisplay('Error loading model', document.getElementById('currentAnimation').textContent);\n                    setModelLoading(false);\n                },\n            );\n        }\n\n        function loadFBX(animationUrl, animationName, crossFadeDuration = 0.5) {\n            currentAnimationUrl = animationUrl;\n            if (!currentMixer || !currentVrm) {\n                /* please load a VRM model first */\n                return;\n            }\n\n            // Stop current action completely to prevent position blending issues\n            if (currentAction) {\n                try {\n                    currentAction.stop();\n                } catch (e) { }\n            }\n\n            // Reset VRM scene and hips bone position to prevent cumulative drift\n            try {\n                currentVrm.scene.position.set(0, 0, 0);\n                // Also reset hips bone position if accessible\n                const hipsBone = currentVrm.humanoid?.getNormalizedBoneNode('hips');\n                if (hipsBone) {\n                    hipsBone.position.set(0, hipsBone.position.y, 0); // Keep Y, reset X/Z\n                }\n            } catch (e) { console.warn('Failed to reset VRM position:', e); }\n\n            updateFileDisplay(document.getElementById('currentModel').textContent, `Loading ${animationName}...`);\n            loadHumanoidAnimation(animationUrl, currentVrm)\n                .then((clip) => {\n                    // Reset position again before playing new animation\n                    try {\n                        currentVrm.scene.position.set(0, 0, 0);\n                    } catch (e) { }\n\n                    const newAction = currentMixer.clipAction(clip);\n                    newAction.reset();\n                    newAction.play();\n                    currentAction = newAction;\n                    updateFileDisplay(document.getElementById('currentModel').textContent, animationName);\n                    if (!initialAnimationApplied) {\n                        initialAnimationApplied = true;\n                        console.log('‚úÖ Animation applied, checking initial ready...');\n                        notifyInitialReadyIfDone();\n                    }\n\n                    // Start expressions after animation has started playing\n                    if (currentVrm) {\n                        setTimeout(() => {\n                            // Only start if not already running\n                            if (!blinkInterval) {\n                                startRandomBlinking(currentVrm);\n                                startRandomSmiling(currentVrm);\n                                startAmbientMicroExpressions(currentVrm);\n                            }\n                        }, 200);\n                    }\n                })\n                .catch((error) => {\n                    /* error loading animation */\n                    updateFileDisplay(document.getElementById('currentModel').textContent, 'Error: ' + error.message);\n                });\n        }\n\n        window.loadRandomFiles = async function () {\n            try {\n                console.log('üé≤ loadRandomFiles called');\n                const randomVRM = getRandomItem(vrmFiles);\n                const randomFBX = getNextAnimation();\n                console.log('üé≤ Selected random VRM:', randomVRM, 'Animation:', randomFBX);\n\n                if (randomVRM && randomFBX) {\n                    const vrmUrl = await getModelURL(randomVRM);\n                    console.log('üì¶ Loading VRM from URL:', vrmUrl);\n                    // Do not start animation immediately; it will auto-play after post-load blur\n                    loadVRM(vrmUrl, randomVRM);\n                    // Start background preloading excluding current selections\n                    startBackgroundPreloading(randomVRM, randomFBX);\n                } else if (randomVRM) {\n                    const vrmUrl = await getModelURL(randomVRM);\n                    console.log('üì¶ Loading VRM from URL:', vrmUrl);\n                    loadVRM(vrmUrl, randomVRM);\n                    startBackgroundPreloading(randomVRM, null);\n                } else {\n                    console.error('‚ùå No VRM files available!');\n                }\n            } catch (e) {\n                console.error('‚ùå Error in loadRandomFiles:', e);\n            }\n        }\n\n        window.loadNextAnimation = async function () {\n            if (!currentVrm || !currentMixer) {\n                alert('Please load a VRM model first');\n                return;\n            }\n            const nextFBX = getNextAnimation();\n            if (nextFBX) {\n                const fbxUrl = await getAnimationURL(nextFBX);\n                const btn = document.getElementById('nextAnimBtn');\n                const originalText = btn.textContent;\n                btn.textContent = 'Loading...';\n                btn.disabled = true;\n                loadFBX(fbxUrl, nextFBX, 0.8);\n                setTimeout(() => {\n                    btn.textContent = originalText;\n                    btn.disabled = false;\n                }, 1500);\n            }\n        }\n\n        // Removed HTML-side background music functions; Swift layer owns playback.\n\n        // Load a specific VRM model by file name (exposed to SwiftUI)\n        window.loadModelByName = async function (modelName) {\n            try {\n                const vrmUrl = await getModelURL(modelName);\n                if (!vrmUrl) return;\n                loadVRM(vrmUrl, modelName);\n                // Optionally kick off background preloading excluding the current selection\n                startBackgroundPreloading(modelName, null);\n            } catch (e) {\n                /* error loading model by name */\n            }\n        }\n\n        // Load a VRM model by direct URL (optional display name)\n        window.loadModelByURL = async function (url, name = 'Remote Model') {\n            try {\n                if (!url) return;\n                loadVRM(url, name);\n                startBackgroundPreloading(null, null);\n            } catch (e) {\n                /* error loading model by URL */\n            }\n        }\n\n        // Load a specific animation by name (exposed to native)\n        window.loadAnimationByName = async function (animName) {\n            try {\n                if (!currentVrm || !currentMixer) {\n                    console.warn('No VRM loaded, cannot load animation');\n                    return;\n                }\n                // Find animation in fbxFiles (case-insensitive match)\n                let matchedName = fbxFiles.find(f => f.toLowerCase() === animName.toLowerCase());\n                if (!matchedName) {\n                    // Try partial match\n                    matchedName = fbxFiles.find(f => f.toLowerCase().includes(animName.toLowerCase()));\n                }\n                if (!matchedName) {\n                    // Try matching without .fbx extension\n                    matchedName = fbxFiles.find(f => f.replace('.fbx', '').toLowerCase() === animName.toLowerCase());\n                }\n                if (matchedName) {\n                    console.log('Loading animation:', matchedName);\n                    const fbxUrl = await getAnimationURL(matchedName);\n                    loadFBX(fbxUrl, matchedName, 0.5);\n                } else {\n                    console.warn('Animation not found:', animName, '- falling back to random');\n                    window.loadNextAnimation();\n                }\n            } catch (e) {\n                console.error('Error loading animation by name:', e);\n            }\n        }\n\n        window.addEventListener('DOMContentLoaded', async function () {\n            // Apply initial background from native if provided\n            try {\n                if (typeof window.initialBackgroundUrl === 'string' && window.initialBackgroundUrl.trim().length) {\n                    const url = window.initialBackgroundUrl.trim();\n                    if (url.toLowerCase().endsWith('.mp4') || url.toLowerCase().endsWith('.webm')) {\n                        // It's a video\n                        if (window.setBackgroundVideo) window.setBackgroundVideo(url);\n                        else if (window.smoothSetBackgroundVideo) window.smoothSetBackgroundVideo(url);\n\n                        // Mark ready immediately to avoid blocking if video takes time\n                        if (!initialBackgroundReady) { initialBackgroundReady = true; notifyInitialReadyIfDone(); }\n                    } else {\n                        document.body.style.backgroundImage = `url('${url}')`;\n                        // Mark ready since background is applied synchronously\n                        if (!initialBackgroundReady) { initialBackgroundReady = true; notifyInitialReadyIfDone(); }\n                    }\n                } else {\n                    // If no background URL provided, mark as ready anyway (use default background)\n                    // This ensures initialReady can be sent even without persisted background\n                    if (!initialBackgroundReady) { initialBackgroundReady = true; notifyInitialReadyIfDone(); }\n                }\n            } catch {\n                // On error, mark background as ready anyway to allow initialReady\n                if (!initialBackgroundReady) { initialBackgroundReady = true; notifyInitialReadyIfDone(); }\n            }\n\n            // Allow native (Swift) to preselect a model name or URL for later, but do not auto-load here.\n            // Swift will explicitly call window.loadModelByName/URL at the appropriate time after preferences/assets are ready.\n            const nativeName = (typeof window.nativeSelectedModelName === 'string' && window.nativeSelectedModelName.trim().length) ? window.nativeSelectedModelName.trim() : null;\n            const nativeURL = (typeof window.nativeSelectedModelURL === 'string' && window.nativeSelectedModelURL.trim().length) ? window.nativeSelectedModelURL.trim() : null;\n            const isReactNative =\n                typeof window.__isReactNativeShell !== 'undefined'\n                    ? !!window.__isReactNativeShell\n                    : typeof window.ReactNativeWebView !== 'undefined';\n            console.log('üîç Initial model context', { nativeName, nativeURL, isReactNative });\n\n            // Auto-load model if provided (for React Native version)\n            if (nativeName) {\n                try {\n                    console.log('üì¶ Loading model by name:', nativeName);\n                    await window.loadModelByName(nativeName);\n                } catch (e) {\n                    console.error('Failed to load model by name:', e);\n                    // Fallback to random model on error\n                    try {\n                        console.log('üîÑ Falling back to random model...');\n                        await window.loadRandomFiles();\n                    } catch (e2) {\n                        console.error('Failed to load random model:', e2);\n                        if (!initialAnimationApplied) { initialAnimationApplied = true; notifyInitialReadyIfDone(); }\n                    }\n                }\n            } else if (nativeURL) {\n                try {\n                    console.log('üì¶ Loading model by URL:', nativeURL);\n                    await window.loadModelByURL(nativeURL);\n                } catch (e) {\n                    console.error('Failed to load model by URL:', e);\n                    // Fallback to random model on error\n                    try {\n                        console.log('üîÑ Falling back to random model...');\n                        await window.loadRandomFiles();\n                    } catch (e2) {\n                        console.error('Failed to load random model:', e2);\n                        if (!initialAnimationApplied) { initialAnimationApplied = true; notifyInitialReadyIfDone(); }\n                    }\n                }\n            } else if (!isReactNative) {\n                // If no model selected, load a random model automatically\n                // This ensures VRM is visible on screen\n                try {\n                    console.log('üé≤ No model selected, loading random model...');\n                    await window.loadRandomFiles();\n                } catch (e) {\n                    console.error('Failed to load random model:', e);\n                    // If random load fails, mark animation as ready anyway\n                    if (!initialAnimationApplied) { initialAnimationApplied = true; notifyInitialReadyIfDone(); }\n                }\n            } else {\n                // Running inside React Native but no persisted selection yet.\n                // Avoid flashing a random model; wait for native to instruct via injected JS.\n                console.log('‚è≥ React Native context detected with no persisted VRM. Waiting for native model load...');\n                if (!initialAnimationApplied) { initialAnimationApplied = true; notifyInitialReadyIfDone(); }\n            }\n\n            // No HTML-side BGM initialization\n        });\n\n        const clock = new THREE.Clock();\n        function animate() {\n            requestAnimationFrame(animate);\n            const deltaTime = clock.getDelta();\n            if (currentMixer) { currentMixer.update(deltaTime); }\n            if (currentVrm) { currentVrm.update(deltaTime); }\n            // No HTML-side BGM ducking\n            // Smoothly move camera and target towards desired state\n            try {\n                // In call mode, continuously track the head to keep framing tight\n                if (__callMode && currentVrm && currentVrm.humanoid) {\n                    const head = currentVrm.humanoid.getNormalizedBoneNode('head');\n                    if (head) {\n                        head.getWorldPosition(__tmpVec3);\n                        // Slight upward bias for pleasing composition\n                        const targetY = __tmpVec3.y;\n                        __camDesiredTarget.set(__tmpVec3.x, targetY, __tmpVec3.z);\n                        // Keep a fixed world-space offset in front of the head\n                        const zOffset = 1.8;\n                        const yOffset = 0.05;\n                        __camDesiredPos.set(__camDesiredTarget.x, targetY + yOffset, __camDesiredTarget.z + zOffset);\n                    }\n                }\n                camera.position.lerp(__camDesiredPos, 0.08);\n                controls.target.lerp(__camDesiredTarget, 0.12);\n                controls.update();\n            } catch { }\n            renderer.render(scene, camera);\n        }\n        animate();\n\n        const gui = new GUI();\n        const params = { timeScale: 1.0, showHelpers: false };\n        gui.add(params, 'timeScale', 0.0, 2.0, 0.001).onChange((value) => {\n            if (currentMixer) { currentMixer.timeScale = value; }\n        });\n        gui.add(params, 'showHelpers').onChange((value) => { helperRoot.visible = value; });\n\n        window.addEventListener('dragover', function (event) {\n            event.preventDefault();\n            event.dataTransfer.dropEffect = 'copy';\n        });\n        window.addEventListener('drop', function (event) {\n            event.preventDefault();\n            const files = event.dataTransfer.files;\n            if (!files) return;\n            const file = files[0];\n            if (!file) return;\n            const fileType = file.name.split('.').pop().toLowerCase();\n            const blob = new Blob([file], { type: 'application/octet-stream' });\n            const url = URL.createObjectURL(blob);\n            if (fileType === 'fbx') {\n                currentAnimationUrl = url;\n                if (currentVrm && currentMixer) {\n                    loadFBX(url, file.name);\n                } else {\n                    alert('Please load a VRM model first before loading animation');\n                }\n            } else if (fileType === 'vrm' || fileType === 'glb' || fileType === 'gltf') {\n                loadVRM(url, file.name);\n            } else {\n                alert('Unsupported file type. Please drop a .vrm, .glb, .gltf, or .fbx file');\n            }\n        });\n\n        window.addEventListener('resize', function () {\n            camera.aspect = window.innerWidth / window.innerHeight;\n            camera.updateProjectionMatrix();\n            renderer.setSize(window.innerWidth, window.innerHeight);\n            // Re-apply desired targets after size changes\n            try { __updateCameraTargetsForMode(); } catch { }\n        });\n\n        // Expose handlers for native SwiftUI buttons\n        (() => {\n            // Dynamically fetched backgrounds\n            let backgroundList = [];\n            let bgIndex = -1;\n            // Guard to sequence background transitions and avoid flicker/race\n            let bgTransitionId = 0;\n\n            async function fetchBackgrounds() {\n                try {\n                    const res = await fetch('https://n8n8n.top/webhook/backgrounds', { mode: 'cors' });\n                    const data = await res.json();\n                    if (Array.isArray(data)) {\n                        backgroundList = data.filter(r => r && (r.image || r.thumbnail));\n                        if (backgroundList.length > 0 && bgIndex < 0) {\n                            // Do not auto-apply a new background on initial load\n                            // Just initialize index - do NOT mark background as ready\n                            // Swift will set the background via setBackgroundImage()\n                            bgIndex = 0;\n                        }\n                    }\n                } catch {\n                    // Don't mark background as ready on error - wait for Swift to set it\n                }\n            }\n\n            function smoothSetBackground(url) {\n                try {\n                    // Hide video if active\n                    const video = document.getElementById('bgVideo');\n                    if (video) {\n                        video.style.opacity = '0';\n                        setTimeout(() => { if (video.style.opacity === '0') { video.pause(); video.style.display = 'none'; } }, 500);\n                    }\n\n                    const overlay = document.getElementById('bgFadeOverlay');\n                    if (!overlay || !url) {\n                        document.body.style.backgroundImage = `url('${url}')`;\n                        // Mark as ready if not already marked (for immediate sets)\n                        if (!initialBackgroundReady) { initialBackgroundReady = true; notifyInitialReadyIfDone(); }\n                        return;\n                    }\n                    const myId = ++bgTransitionId;\n                    const img = new Image();\n                    img.crossOrigin = 'anonymous';\n                    img.onload = () => {\n                        if (myId !== bgTransitionId) return; // superseded\n\n                        // Step 1: Quick fade to white/transparent (flash effect)\n                        overlay.style.transition = 'opacity 150ms ease-out';\n                        overlay.style.backgroundImage = 'none';\n                        overlay.style.backgroundColor = 'rgba(255, 255, 255, 0.15)';\n                        overlay.style.opacity = '1';\n\n                        // Step 2: After flash, set new background and fade in\n                        setTimeout(() => {\n                            if (myId !== bgTransitionId) return;\n                            overlay.style.transition = 'none';\n                            overlay.style.backgroundColor = 'transparent';\n                            overlay.style.backgroundImage = `url('${url}')`;\n                            overlay.style.opacity = '0';\n                            void overlay.offsetWidth; // reflow\n\n                            // Step 3: Smooth fade in of new background\n                            overlay.style.transition = 'opacity 350ms ease-in';\n                            overlay.style.opacity = '1';\n\n                            // Step 4: Complete transition\n                            setTimeout(() => {\n                                if (myId !== bgTransitionId) return;\n                                document.body.style.backgroundImage = `url('${url}')`;\n                                overlay.style.opacity = __callMode ? '1' : '0';\n                                // Ensure blur state persists after transition\n                                if (__callMode) {\n                                    overlay.classList.add('call-blur');\n                                } else {\n                                    overlay.classList.remove('call-blur');\n                                }\n                                // Mark background as ready after transition completes\n                                if (!initialBackgroundReady) { initialBackgroundReady = true; notifyInitialReadyIfDone(); }\n                            }, 380);\n                        }, 160);\n                    };\n                    img.onerror = () => {\n                        if (myId !== bgTransitionId) return;\n                        document.body.style.backgroundImage = `url('${url}')`;\n                        // Mark as ready even on error (background was set)\n                        if (!initialBackgroundReady) { initialBackgroundReady = true; notifyInitialReadyIfDone(); }\n                        // Maintain blur state\n                        if (__callMode) {\n                            overlay.style.backgroundImage = `url('${url}')`;\n                            overlay.classList.add('call-blur');\n                            overlay.style.opacity = '1';\n                        } else {\n                            overlay.classList.remove('call-blur');\n                            overlay.style.opacity = '0';\n                        }\n                    };\n                    img.src = url;\n                } catch { }\n            }\n\n            function smoothSetBackgroundVideo(url) {\n                try {\n                    const video = document.getElementById('bgVideo');\n                    const overlay = document.getElementById('bgFadeOverlay');\n                    if (!video || !url) return;\n\n                    const myId = ++bgTransitionId;\n\n                    // Step 1: Show flash effect\n                    if (overlay) {\n                        overlay.style.transition = 'opacity 150ms ease-out';\n                        overlay.style.backgroundImage = 'none';\n                        overlay.style.backgroundColor = 'rgba(255, 255, 255, 0.15)';\n                        overlay.style.opacity = '1';\n                    }\n\n                    // Reset video state\n                    video.style.display = 'block';\n                    video.style.opacity = '0';\n                    video.src = url;\n                    video.load();\n\n                    // Wait for video to be ready before fading in\n                    const onCanPlay = () => {\n                        if (myId !== bgTransitionId) return; // Superseded by another transition\n\n                        video.removeEventListener('canplay', onCanPlay);\n                        video.removeEventListener('error', onError);\n\n                        // Start playing\n                        video.play().catch(e => console.error('Video play error:', e));\n\n                        // Step 2: Clear flash and fade in video\n                        setTimeout(() => {\n                            if (overlay) {\n                                overlay.style.transition = 'none';\n                                overlay.style.backgroundColor = 'transparent';\n                                overlay.style.backgroundImage = 'none';\n                                overlay.style.opacity = '0';\n                            }\n\n                            // Fade in video smoothly\n                            video.style.transition = 'opacity 350ms ease-in';\n                            video.style.opacity = '1';\n\n                            if (!initialBackgroundReady) { initialBackgroundReady = true; notifyInitialReadyIfDone(); }\n                        }, 160);\n                    };\n\n                    const onError = () => {\n                        video.removeEventListener('canplay', onCanPlay);\n                        video.removeEventListener('error', onError);\n                        console.error('Video load error for:', url);\n                        // Hide video on error\n                        video.style.display = 'none';\n                        if (overlay) {\n                            overlay.style.backgroundColor = 'transparent';\n                            overlay.style.opacity = '0';\n                        }\n                        if (!initialBackgroundReady) { initialBackgroundReady = true; notifyInitialReadyIfDone(); }\n                    };\n\n                    video.addEventListener('canplay', onCanPlay, { once: true });\n                    video.addEventListener('error', onError, { once: true });\n\n                } catch (e) { console.error(e); }\n            }\n\n            // Public controls\n            window.nextBackground = function () {\n                try {\n                    if (!backgroundList.length) { fetchBackgrounds(); return; }\n                    bgIndex = (bgIndex + 1) % backgroundList.length;\n                    const item = backgroundList[bgIndex];\n                    if (item.video_url) {\n                        smoothSetBackgroundVideo(item.video_url);\n                    } else {\n                        const url = item.image || item.thumbnail;\n                        if (url) smoothSetBackground(url);\n                    }\n                } catch { }\n            };\n            window.prevBackground = function () {\n                try {\n                    if (!backgroundList.length) { fetchBackgrounds(); return; }\n                    bgIndex = (bgIndex - 1 + backgroundList.length) % backgroundList.length;\n                    const item = backgroundList[bgIndex];\n                    if (item.video_url) {\n                        smoothSetBackgroundVideo(item.video_url);\n                    } else {\n                        const url = item.image || item.thumbnail;\n                        if (url) smoothSetBackground(url);\n                    }\n                } catch { }\n            };\n            window.setBackgroundImage = function (url) {\n                try {\n                    // Check if it looks like a video if calling setBackgroundImage generically\n                    if (url && (url.toLowerCase().endsWith('.mp4') || url.toLowerCase().endsWith('.webs') || url.toLowerCase().endsWith('.webm'))) {\n                        smoothSetBackgroundVideo(url);\n                    } else {\n                        if (url) smoothSetBackground(url);\n                    }\n                    // Try to align bgIndex with the provided url if it exists in list\n                    const i = backgroundList.findIndex(r => r.image === url || r.thumbnail === url || r.video_url === url);\n                    if (i >= 0) bgIndex = i;\n                    // Maintain call mode blur if active\n                    if (__callMode) { __applyCallBackgroundBlur(true); }\n                } catch { }\n            };\n            window.setBackgroundVideo = function (url) {\n                if (url) smoothSetBackgroundVideo(url);\n                // Try align index\n                const i = backgroundList.findIndex(r => r.video_url === url);\n                if (i >= 0) bgIndex = i;\n            };\n\n            // Expose current background name to native (kept for backward compatibility)\n            window.getCurrentRoomName = function () {\n                try {\n                    if (!backgroundList.length || bgIndex < 0) return '';\n                    return backgroundList[bgIndex]?.name || '';\n                } catch { return ''; }\n            };\n            // New function name for consistency\n            window.getCurrentBackgroundName = function () {\n                try {\n                    if (!backgroundList.length || bgIndex < 0) return '';\n                    return backgroundList[bgIndex]?.name || '';\n                } catch { return ''; }\n            };\n\n            // Initial fetch\n            fetchBackgrounds();\n            window.playRandomGreeting = async function () {\n                try {\n                    const greetings = [\"Standing Greeting.fbx\", \"Hand Raising.fbx\", \"Blow A Kiss.fbx\", \"Happy.fbx\"];\n                    const randomName = getRandomItem(greetings);\n                    if (randomName) {\n                        console.log('üé≤ Playing random greeting:', randomName);\n                        // Use getAnimationURL to benefit from caching and cors handling\n                        const url = await getAnimationURL(randomName);\n                        if (url) {\n                            loadFBX(url, randomName, 0.3);\n                        }\n                    }\n                } catch (e) {\n                    console.error('Failed to play random greeting:', e);\n                }\n            };\n            window.triggerDance = function () {\n                try { window.loadNextAnimation && window.loadNextAnimation(); } catch { }\n            };\n            window.triggerLove = function () {\n                if (!currentVrm || !currentVrm.expressionManager) return;\n                const names = ['happy', 'joy', 'fun', 'relaxed'];\n                let t0 = performance.now();\n                const dur = 0.9;\n                const maxV = 0.35;\n                const setVal = (v) => { for (const n of names) { try { currentVrm.expressionManager.setValue(n, v); } catch { } } };\n                const step = (ts) => {\n                    const t = (ts - t0) / 1000;\n                    if (t <= dur) {\n                        const p = t / dur;\n                        const v = p < 0.5 ? (maxV * (0.5 * (1 - Math.cos(Math.PI * (p / 0.5))))) : (maxV * (1 - 0.5 * (1 - Math.cos(Math.PI * ((p - 0.5) / 0.5)))));\n                        setVal(Math.max(0, Math.min(maxV, v)));\n                        requestAnimationFrame(step);\n                    } else {\n                        setVal(0.0);\n                    }\n                };\n                requestAnimationFrame(step);\n            };\n        })();\n\n        // Parallax application: move background subtly with device tilt\n        window.applyParallax = (dx, dy) => {\n            try {\n                const overlay = document.getElementById('bgFadeOverlay');\n                const x = Math.max(-100, Math.min(100, Number(dx) || 0));\n                const y = 0; // lock Y parallax\n                // Translate overlay for smooth GPU movement\n                if (overlay) {\n                    // Preserve scale applied in call-blur by appending translate\n                    const translate = `translate(${x * 0.9}px, ${y}px)`;\n                    overlay.style.transform = overlay.classList.contains('call-blur') ? `scale(1.03) ${translate}` : translate;\n                }\n                // Also nudge body background position as a fallback\n                document.body.style.backgroundPosition = `calc(50% + ${x * 0.5}px) 50%`;\n            } catch { }\n        };\n\n        // Lipsync: set mouth openness [0..1]; damped smoothing\n        let __mouthLerp = 0;\n        let __speechActiveUntil = 0; // ms timestamp while speech is considered active\n        let __lastMouthLogTime = 0;\n        window.setMouthOpen = (v) => {\n            try {\n                // Amplify and bias for stronger lipsync\n                const raw = Math.max(0, Math.min(1, Number(v) || 0));\n                // Debug log (throttled)\n                const now = performance.now();\n                if (raw > 0.1 && now - __lastMouthLogTime > 1000) {\n                    __lastMouthLogTime = now;\n                    console.log('üëÑ [Lipsync] setMouthOpen called, raw:', raw.toFixed(2), 'hasVRM:', !!currentVrm, 'hasExpMgr:', !!currentVrm?.expressionManager);\n                }\n                // Gain and soft gamma curve make quiet sounds visible and loud sounds pop\n                const gain = 3.0;            // stronger amplification\n                const gamma = 0.65;          // stronger curve\n                const biased = Math.pow(Math.min(1, raw * gain), gamma);\n                // Much faster response for more realistic lipsync\n                __mouthLerp = 0.15 * __mouthLerp + 0.85 * biased;\n                // Mark speech as active for blink scheduling\n                if (raw > 0.02) { __speechActiveUntil = performance.now() + 900; }\n                if (currentVrm && currentVrm.expressionManager) {\n                    // Allow a bigger apparent opening, then clamp\n                    const main = Math.max(0, Math.min(1, __mouthLerp * 1.35));\n                    // Emphasize \"aa\" most, others slightly lower to avoid flat mouth shapes\n                    const map = [\n                        ['aa', main],\n                        ['ee', main * 0.8],\n                        ['ih', main * 0.75],\n                        ['oh', Math.min(1, main * 1.1)],\n                        ['ou', Math.min(1, main * 1.05)],\n                        ['teethOpen', main * 0.6],\n                    ];\n                    for (const [n, val] of map) {\n                        try { currentVrm.expressionManager.setValue(n, val); } catch { }\n                    }\n                    // Fallback vowel keys used by some rigs (A,E,I,O,U)\n                    const upperMap = [\n                        ['A', main],\n                        ['E', main * 0.8],\n                        ['I', main * 0.75],\n                        ['O', Math.min(1, main * 1.1)],\n                        ['U', Math.min(1, main * 1.05)],\n                    ];\n                    for (const [n, val] of upperMap) {\n                        try { currentVrm.expressionManager.setValue(n, val); } catch { }\n                    }\n                }\n                // No HTML-side BGM ducking; managed in Swift\n            } catch { }\n        };\n\n        // Removed applyBgmDucking; Swift manages audio levels\n    </script>\n</body>\n\n</html>";
